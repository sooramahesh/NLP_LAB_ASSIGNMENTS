{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/RU7lUoLCsaUWyzR2UstQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sooramahesh/NLP_LAB_ASSIGNMENTS/blob/main/NLP_ASSIGNMENT_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NLP ASSIGNMENT-6**\n",
        "\n",
        "\n",
        "**2203A51159**\n",
        "\n",
        "**SOORA MAHESH**\n",
        "\n",
        "**BATCH: 05**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LDs2SqxXltPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Load data fromkeras.datasets and perform following computational analysis:-**\n",
        "\n",
        "  **(a) Preprocessing of the Data**\n",
        "\n",
        " **(b) Divide data into training and testing data set**\n",
        "\n",
        " **(c) Build the Gated Recurrent Units (GRU) Model**\n",
        "\n",
        " **(d) Training the GRU Model**\n",
        "\n",
        " **(e) Text Generation Using the Trained Model**\n",
        "\n",
        "  **(f) Evaluate Model’s accuracy**"
      ],
      "metadata": {
        "id": "E2FMGP0filfw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ih12o7UxVnCr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, LSTM, Embedding, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading and Preprocessing the Data\n",
        "num_words = 10000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "max_len = 200\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "kIXRqJYQWlqY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model building for GRU\n",
        "def build_gru_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_words, 128, input_length=max_len))\n",
        "    model.add(GRU(128, return_sequences=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "z0Pe4-n7XCAH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model building for LSTM\n",
        "def build_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(num_words, 128, input_length=max_len))\n",
        "    model.add(LSTM(128, return_sequences=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "-pST5qw_XFzT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate GRU model\n",
        "gru_model = build_gru_model()\n",
        "gru_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07SG4331XIf-",
        "outputId": "5e52114c-f1e8-456b-8ee6-f55b6b1524aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 608ms/step - accuracy: 0.7013 - loss: 0.5434 - val_accuracy: 0.8471 - val_loss: 0.3755\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 688ms/step - accuracy: 0.8988 - loss: 0.2635 - val_accuracy: 0.8754 - val_loss: 0.3009\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 597ms/step - accuracy: 0.9411 - loss: 0.1617 - val_accuracy: 0.8754 - val_loss: 0.3068\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 694ms/step - accuracy: 0.9665 - loss: 0.0969 - val_accuracy: 0.8722 - val_loss: 0.3646\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 594ms/step - accuracy: 0.9787 - loss: 0.0638 - val_accuracy: 0.8636 - val_loss: 0.4356\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d451aceace0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate LSTM model\n",
        "lstm_model = build_lstm_model()\n",
        "lstm_model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_5esPiFXKEe",
        "outputId": "e0074285-f8de-443f-fd63-0d98f1a09e36"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 575ms/step - accuracy: 0.6819 - loss: 0.5616 - val_accuracy: 0.8304 - val_loss: 0.3839\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 582ms/step - accuracy: 0.8998 - loss: 0.2575 - val_accuracy: 0.8541 - val_loss: 0.3563\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 579ms/step - accuracy: 0.9220 - loss: 0.2063 - val_accuracy: 0.8670 - val_loss: 0.3563\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 585ms/step - accuracy: 0.9534 - loss: 0.1315 - val_accuracy: 0.8406 - val_loss: 0.3929\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 581ms/step - accuracy: 0.9663 - loss: 0.1004 - val_accuracy: 0.8648 - val_loss: 0.4822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d4519ab7be0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Compare accuracy of Long sort term memory and Gated recurrent Unit models for text generation using data from tensorflow.keras.datasets.**"
      ],
      "metadata": {
        "id": "lIkGfwYRktno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare accuracies\n",
        "gru_accuracy = gru_model.evaluate(X_test, y_test)\n",
        "lstm_accuracy = lstm_model.evaluate(X_test, y_test)\n",
        "print(f\"GRU Accuracy: {gru_accuracy[1]*100:.2f}%\")\n",
        "print(f\"LSTM Accuracy: {lstm_accuracy[1]*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHb5URYuXN3_",
        "outputId": "8c82853e-b4ce-47c7-de04-dda230c192dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 55ms/step - accuracy: 0.8627 - loss: 0.4425\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 108ms/step - accuracy: 0.8634 - loss: 0.4983\n",
            "GRU Accuracy: 86.36%\n",
            "LSTM Accuracy: 86.48%\n"
          ]
        }
      ]
    }
  ]
}